{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "=========  ===============================================<br>\n",
    "    run                 task<br>\n",
    "=========  ===============================================<br>\n",
    "    1          Baseline, eyes open<br>\n",
    "    2          Baseline, eyes closed<br>\n",
    "3, 7, 11       Motor execution: left vs right hand<br>\n",
    "4, 8, 12       Motor imagery: left vs right hand<br>\n",
    "5, 9, 13       Motor execution: hands vs feet<br>\n",
    "6, 10, 14      Motor imagery: hands vs feet<br>\n",
    "=========  ===============================================<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score, train_test_split\n",
    "\n",
    "from mne import Epochs, pick_types, events_from_annotations\n",
    "from mne.channels import read_layout\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne.decoding import CSP\n",
    "import mne\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "# from ipywidgets import *\n",
    "from EEGNet import *\n",
    "\n",
    "%matplotlib qt5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dataset from https://physionet.org/pn4/eegmmidb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raws_list = []\n",
    "for i in range(1,110):\n",
    "    try:\n",
    "        runs = [1,2,3,4,5,6, 7,8,9,10, 11,12,13,14] # left vs right hand\n",
    "        raws_list.append(eegbci.load_data(i, runs))\n",
    "    except Exception as e:\n",
    "        print(i,' => ' ,e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# #############################################################################\n",
    "# # Set parameters and read data\n",
    "\n",
    "# avoid classification of evoked responses by using epochs that start 1s after\n",
    "# cue onset.\n",
    "# tmin, tmax = -1., 4.\n",
    "event_id = dict(left=1, right=2)\n",
    "subjects = [i for i in range(1,2)]\n",
    "runs = [4, 8, 12]  # Motor imagery: left hand vs right hand\n",
    "\n",
    "raw_fnames = []\n",
    "for i in subjects:\n",
    "    for f in eegbci.load_data(i, runs):\n",
    "        raw_fnames.append(f)\n",
    "raw = concatenate_raws([read_raw_edf(f, preload=True) for f in raw_fnames])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization & Underestanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Info | 16 non-empty fields\n",
       "    bads : list | 0 items\n",
       "    ch_names : list | Fc5., Fc3., Fc1., Fcz., Fc2., Fc4., Fc6., C5.., C3.., ...\n",
       "    chs : list | 64 items (EEG: 64)\n",
       "    comps : list | 0 items\n",
       "    custom_ref_applied : bool | False\n",
       "    dev_head_t : Transform | 3 items\n",
       "    events : list | 0 items\n",
       "    highpass : float | 0.0 Hz\n",
       "    hpi_meas : list | 0 items\n",
       "    hpi_results : list | 0 items\n",
       "    lowpass : float | 80.0 Hz\n",
       "    meas_date : tuple | 2009-08-12 16:15:00 GMT\n",
       "    nchan : int | 64\n",
       "    proc_history : list | 0 items\n",
       "    projs : list | 0 items\n",
       "    sfreq : float | 160.0 Hz\n",
       "    acq_pars : NoneType\n",
       "    acq_stim : NoneType\n",
       "    ctf_head_t : NoneType\n",
       "    description : NoneType\n",
       "    dev_ctf_t : NoneType\n",
       "    dig : NoneType\n",
       "    experimenter : NoneType\n",
       "    file_id : NoneType\n",
       "    gantry_angle : NoneType\n",
       "    hpi_subsystem : NoneType\n",
       "    kit_system_id : NoneType\n",
       "    line_freq : NoneType\n",
       "    meas_id : NoneType\n",
       "    proj_id : NoneType\n",
       "    proj_name : NoneType\n",
       "    subject_info : NoneType\n",
       "    xplotter_layout : NoneType\n",
       ">"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 2902240)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip channel names of \".\" characters\n",
    "raw.rename_channels(lambda x: x.strip('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the montage of sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-55f34095d476>:2: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: ['T9', 'T10']. Their position has been left untouched.\n",
      "  raw.set_montage(montage)\n"
     ]
    }
   ],
   "source": [
    "montage = mne.channels.read_montage('biosemi64')\n",
    "raw.set_montage(montage)\n",
    "# raw.plot_sensors('3d')\n",
    "%matplotlib qt5\n",
    "# raw.plot_psd(fmax=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['T1', 'T2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2205, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_from_annotations(raw, event_id=dict(T1=1, T2=2))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 147 contiguous segments\n",
      "Setting up band-pass filter from 7 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 7.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 265 samples (1.656 sec)\n",
      "\n",
      "Used Annotations descriptions: ['T1', 'T2']\n",
      "2205 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 2205 events and 801 original time points ...\n",
      "5 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "# Apply band-pass filter\n",
    "raw.filter(7., 30., fir_design='firwin', skip_by_annotation='edge')\n",
    "\n",
    "events, _ = events_from_annotations(raw, event_id=dict(T1=1, T2=2))\n",
    "\n",
    "picks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                   exclude='bads')\n",
    "\n",
    "# Read epochs (train will be done only between 1 and 2s)\n",
    "# Testing will be done with a running classifier\n",
    "epochs = Epochs(raw, events, event_id, -1, 4, proj=True, picks=picks,\n",
    "                baseline=None, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 64, 801)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.get_data().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-set & Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_train = epochs.copy().crop(tmin=1., tmax=2)\n",
    "labels = epochs_train.events[:, -1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 64, 161)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_train.get_data().shape\n",
    "# labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.DataFrame(events, columns = ['time','x','event'])\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# ax.scatter(df.index, df['event'])\n",
    "\n",
    "# indexA = np.array(df.index[df['event']==3])\n",
    "# for i in indexA:\n",
    "#     ax.axvline(x=i, ymin=0, ymax=1, c='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mne.viz.plot_events(events, raw.info['sfreq'], raw.first_samp,\n",
    "#                     event_id=event_id)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract data from the first 5 channels\n",
    "# n_ch = 5\n",
    "# sfreq = raw.info['sfreq']\n",
    "# data, times = raw[:n_ch, int(sfreq * 1):int(sfreq * 100)]\n",
    "\n",
    "# fig = plt.subplots(figsize=(10,8))\n",
    "# plt.plot(times, data.T);\n",
    "# plt.xlabel('Seconds')\n",
    "# plt.ylabel('$\\mu V$')\n",
    "# plt.title('Channels: 1-' + str(n_ch));\n",
    "# plt.legend(raw.ch_names[:n_ch]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test spilt \n",
    "### using mne method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a monte-carlo cross-validation generator (reduce variance):\n",
    "scores = []\n",
    "epochs_data = epochs.get_data()\n",
    "epochs_data_train = epochs_train.get_data()\n",
    "cv = ShuffleSplit(10, test_size=0.25, random_state=42)\n",
    "cv_split = cv.split(epochs_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = []\n",
    "# for train_idx, test_idx in cv_split:\n",
    "#     y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "#     print(epochs_data_train[train_idx])\n",
    "#     c.append(csp.fit_transform(epochs_data_train[train_idx], y_train))\n",
    "# # c[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = svm.SVC(gamma='auto')\n",
    "# classifier = LogisticRegression(solver='lbfgs')\n",
    "# classifier = LinearDiscriminantAnalysis()\n",
    "# classifier = GaussianNB()\n",
    "# classifier = LassoLarsCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csp = CSP(n_components=2, reg=None, log=True, norm_trace=False)\n",
    "\n",
    "# # Use scikit-learn Pipeline with cross_val_score function\n",
    "# clf = Pipeline([('CSP', csp), ('Classifier', classifier)])\n",
    "# scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=1)\n",
    "\n",
    "# # Printing the results\n",
    "# class_balance = np.mean(labels == labels[0])\n",
    "# class_balance = max(class_balance, 1. - class_balance)\n",
    "# print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "#                                                           class_balance))\n",
    "\n",
    "# # plot CSP patterns estimated on full data for visualization\n",
    "# csp.fit_transform(epochs_data, labels)\n",
    "\n",
    "# layout = read_layout('EEG1005')\n",
    "# csp.plot_patterns(epochs.info, layout=layout, ch_type='eeg',\n",
    "#                   units='Patterns (AU)', size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape\n",
    "labels = labels.reshape((labels.shape[0],1))\n",
    "epochs_data_train = epochs_data_train.reshape((epochs_data_train.shape[0],1, epochs_data_train.shape[1], epochs_data_train.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train-set-X: (1760, 1, 64, 161) \n",
      "shape of test-set-X: (440, 1, 64, 161)\n",
      "shape of train-set-y: (1760, 1) \n",
      "shape of test-set-y: (440, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(epochs_data_train, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print('shape of train-set-X: {} \\nshape of test-set-X: {}'.format(X_train.shape, X_test.shape))\n",
    "print('shape of train-set-y: {} \\nshape of test-set-y: {}'.format(y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\InstalledApps\\WindowsApps\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\InstalledApps\\WindowsApps\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "import EEGNet\n",
    "batch_size = 50\n",
    "# model = EEGNet.my_EEGNet(input_shape=(64,161), batch_size=None,n_classes=2)\n",
    "# model = EEGNet.EEGNet(2,Samples=161, F1=8, kernLength=20)\n",
    "model = EEGNet.EEGNet(2, Chans = 64, Samples = 161, \n",
    "             dropoutRate = 0.5, kernLength = 64, F1 = 8, \n",
    "             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(lr=0.0001)\n",
    "model.compile(optimizer ,'sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 64, 161)        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 8, 64, 161)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 8, 64, 161)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC (None, 16, 1, 161)        1024      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16, 1, 161)        64        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16, 1, 161)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 16, 1, 40)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 1, 40)         0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d (SeparableC (None, 16, 1, 16)         1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16, 1, 16)         64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 1, 16)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 16, 1, 2)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 1, 2)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 3,042\n",
      "Trainable params: 2,962\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1760 samples, validate on 440 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d/Conv2D}}]]\n\t [[{{node metrics/acc/div_no_nan}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-290679d29565>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\InstalledApps\\WindowsApps\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\InstalledApps\\WindowsApps\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\InstalledApps\\WindowsApps\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32mD:\\InstalledApps\\WindowsApps\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\InstalledApps\\WindowsApps\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d/Conv2D}}]]\n\t [[{{node metrics/acc/div_no_nan}}]]"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=10,epochs=100,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23974579588>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 1, 64, 801)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
